{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/sam/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# Step 1: Load the BLIP model and processor\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the image\n",
    "def load_image(image_path):\n",
    "    if image_path.startswith(\"http\"):\n",
    "        image = Image.open(requests.get(image_path, stream=True).raw).convert(\"RGB\")\n",
    "    else:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "# Step 3: Generate caption\n",
    "def generate_caption(image_path):\n",
    "    image = load_image(image_path)\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs)\n",
    "    caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/disk3/eric/VG_arma3_roboflow/images/*.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/disk3/eric/VG_arma3_roboflow/images/frame_7430.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7560.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6590.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4830.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2730.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3260.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6640.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3230.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4600.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4570.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5170.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5280.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2480.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6580.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8650.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5190.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3640.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3520.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4840.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4440.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3710.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3290.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4740.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5580.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6510.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4500.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3000.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7620.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2810.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6700.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7670.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4560.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4390.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2900.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4470.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2870.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7500.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3850.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2820.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3420.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2740.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8550.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6660.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6740.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7610.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5320.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5410.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2980.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4550.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6480.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3360.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2510.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5110.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4630.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5440.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3180.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7570.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6670.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2750.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3620.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4430.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3570.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8610.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7510.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3680.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8660.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3560.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8680.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2680.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3660.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3490.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3450.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4680.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2660.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4490.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3880.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2670.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4620.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8700.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4540.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5570.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2600.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6750.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2970.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2790.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2950.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3330.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3780.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3920.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2580.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3120.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2410.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5270.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5560.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6140.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6570.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4530.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5500.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2710.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2610.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3010.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8570.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5340.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6560.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7070.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6630.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6180.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3630.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4400.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2540.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6760.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3510.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8600.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3610.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3150.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2770.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2520.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5090.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7030.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4720.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7580.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7090.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7480.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7530.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3730.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3370.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6530.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7040.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3250.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6220.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5160.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5590.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4800.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3110.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8690.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7410.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6160.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3750.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2470.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4420.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3550.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3440.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4640.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2490.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7060.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3300.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2650.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6780.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4450.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8670.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2880.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3940.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8640.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7050.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3860.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2640.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5120.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7080.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5380.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3310.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3740.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5240.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3720.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3020.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5540.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3530.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5450.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5610.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3810.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2590.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2700.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3670.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6610.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7590.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3200.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7600.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4410.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3390.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3910.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8710.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2530.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7420.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3210.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6460.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7540.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7470.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3870.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5510.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2720.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5220.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3930.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2840.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2390.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3840.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4480.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5430.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3950.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6470.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6540.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5300.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6680.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4810.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2630.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4700.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4580.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7660.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2690.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5530.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6150.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5310.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8560.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6500.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3460.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2800.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3890.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4370.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6720.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3050.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3170.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8580.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7400.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2780.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7440.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5490.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6620.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3580.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4770.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2990.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2960.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2860.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8630.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4690.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2930.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6170.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6730.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3500.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3060.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3380.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5400.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4780.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5250.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6690.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3350.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2910.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2550.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7650.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6190.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8590.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3600.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6550.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3140.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7550.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4460.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4730.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2460.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5390.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2620.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4610.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3040.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5200.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3280.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3830.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5180.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2500.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3270.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4790.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4520.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5150.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5470.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5210.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2430.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5290.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7460.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3900.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5600.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5230.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7490.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3320.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6200.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5350.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3220.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2920.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3650.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6240.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5420.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3430.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3090.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7450.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3540.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7640.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5360.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5460.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4510.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6770.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2940.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2760.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5140.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4660.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3470.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8540.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6600.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4670.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4760.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3690.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3790.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6650.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6790.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5370.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7520.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6490.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2440.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5080.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6710.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3410.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3100.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3800.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6230.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3480.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3030.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5330.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5480.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3700.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3590.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4750.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3240.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4650.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2850.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3340.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3770.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6210.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5520.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3160.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5260.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3080.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_6520.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3820.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3400.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2570.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4590.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2420.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4710.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_8620.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3190.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2560.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2450.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3070.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5100.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5550.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3130.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4380.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_5130.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7020.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2400.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2830.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_4820.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_3760.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_7630.jpg',\n",
       " '/disk3/eric/VG_arma3_roboflow/images/frame_2890.jpg']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_7430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/sam/lib/python3.9/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption: a screenshot of a gun in the woods\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_7560.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/sam/lib/python3.9/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption: the last frontier - screenshote\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_6590.jpg\n",
      "Generated Caption: a screenshot of a gun in front of a wall\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_4830.jpg\n",
      "Generated Caption: a screenshot of a road with trees and bushes\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_2730.jpg\n",
      "Generated Caption: the sniper sniper in battlefield\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_3260.jpg\n",
      "Generated Caption: a rifle in the desert with a rifle scope\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_6640.jpg\n",
      "Generated Caption: a screenshot of a gun in the woods\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_3230.jpg\n",
      "Generated Caption: a rifle in the desert\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_4600.jpg\n",
      "Generated Caption: a screenshot of a rifle in the game call\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_4570.jpg\n",
      "Generated Caption: a screenshot of a building with a road in the background\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_5170.jpg\n",
      "Generated Caption: the last days of fallout fallout 2\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_5280.jpg\n",
      "Generated Caption: the first person shooter in call of the wild\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_2480.jpg\n",
      "Generated Caption: the road in the game, with a dirt road and trees\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_6580.jpg\n",
      "Generated Caption: a screenshot of a gun in front of a stone wall\n",
      "filename /disk3/eric/VG_arma3_roboflow/images/frame_8650.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m img_paths \u001b[38;5;241m=\u001b[39m glob(img_path)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m img_paths:\n\u001b[0;32m----> 6\u001b[0m     caption \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_caption\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Caption:\u001b[39m\u001b[38;5;124m\"\u001b[39m, caption)\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mgenerate_caption\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m image \u001b[38;5;241m=\u001b[39m load_image(image_path)\n\u001b[1;32m     12\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(image, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m caption \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caption\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/transformers/models/blip/modeling_blip.py:1062\u001b[0m, in \u001b[0;36mBlipForConditionalGeneration.generate\u001b[0;34m(self, pixel_values, input_ids, attention_mask, **generate_kwargs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03mOverrides *generate* function to be able to use the model as a conditional generator\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1062\u001b[0m vision_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m image_embeds \u001b[38;5;241m=\u001b[39m vision_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1066\u001b[0m image_attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(image_embeds\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(image_embeds\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/transformers/models/blip/modeling_blip.py:688\u001b[0m, in \u001b[0;36mBlipVisionModel.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify pixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    686\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(pixel_values)\n\u001b[0;32m--> 688\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    696\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_layernorm(last_hidden_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/transformers/models/blip/modeling_blip.py:628\u001b[0m, in \u001b[0;36mBlipEncoder.forward\u001b[0;34m(self, inputs_embeds, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    621\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    622\u001b[0m         encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    623\u001b[0m         hidden_states,\n\u001b[1;32m    624\u001b[0m         attention_mask,\n\u001b[1;32m    625\u001b[0m         output_attentions,\n\u001b[1;32m    626\u001b[0m     )\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 628\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/transformers/models/blip/modeling_blip.py:413\u001b[0m, in \u001b[0;36mBlipEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    411\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    412\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm2(hidden_states)\n\u001b[0;32m--> 413\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m residual\n\u001b[1;32m    417\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/transformers/models/blip/modeling_blip.py:371\u001b[0m, in \u001b[0;36mBlipMLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 371\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(hidden_states)\n\u001b[1;32m    373\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    img_path = \"/disk3/eric/VG_arma3_roboflow/images/*.jpg\"\n",
    "    img_paths = glob(img_path)\n",
    "    for path in img_paths:\n",
    "        caption = generate_caption(path)\n",
    "        print(\"Generated Caption:\", caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
